{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, n_heads, emb_dim, in_proj_bias=True, out_proj_bias=True):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.in_proj = nn.Linear(emb_dim, 3 * emb_dim, bias=in_proj_bias)\n",
    "        self.out_proj = nn.Linear(emb_dim, emb_dim, bias=out_proj_bias)\n",
    "        self.d_heads = emb_dim // n_heads\n",
    "\n",
    "    def forward(self, x, causal_mask=False):\n",
    "        batch_size, seq_len, d_embed = x.shape\n",
    "        interim_shape = (batch_size, seq_len, self.n_heads, self.d_heads)\n",
    "\n",
    "        q, k, v = self.in_proj(x).chunk(3, dim=-1)\n",
    "\n",
    "        q = q.view(interim_shape).transpose(1, 2)\n",
    "        k = k.view(interim_shape).transpose(1, 2)\n",
    "        v = v.view(interim_shape).transpose(1, 2)\n",
    "\n",
    "        weight = q @ k.transpose(-1, -2)\n",
    "\n",
    "        if causal_mask:\n",
    "            mask = torch.ones_like(weight, dtype=torch.bool).triu(1)\n",
    "            weight.masked_fill_(mask, float('-inf'))\n",
    "\n",
    "        weight /= math.sqrt(self.d_heads)\n",
    "        weight = F.softmax(weight, dim=-1)\n",
    "        out = weight @ v\n",
    "        out = out.transpose(1, 2).reshape((batch_size, seq_len, d_embed))\n",
    "        return self.out_proj(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "      super().__init__()\n",
    "      self.groupnorm = nn.GroupNorm(32, channels)\n",
    "      self.attention = SelfAttention(1, channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "      # x: (batch_size, channels, h, w)\n",
    "      residual = x.clone()\n",
    "\n",
    "      # (batch_size, channels, h, w) -> (batch_size, channels, h, w)\n",
    "      x = self.groupnorm(x)\n",
    "\n",
    "      n, c, h, w = x.shape\n",
    "\n",
    "      # (batch_size, channels, h, w) -> (batch_size, channels, h * w)\n",
    "      x = x.view((n, c, h * w))\n",
    "\n",
    "      # (batch_size, channels, h * w) -> (batch_size, h * w, channels)\n",
    "      x = x.transpose(-1, -2)\n",
    "\n",
    "      # perform self-attention without mask\n",
    "      # (batch_size, h * w, channels) -> (batch_size, h * w, channels)\n",
    "      x = self.attention(x)\n",
    "\n",
    "      # (batch_size, h * w, channels) -> (batch_size, channels, h * w)\n",
    "      x = x.transpose(-1, -2)\n",
    "\n",
    "      # (batch_size, channels, h * w) -> (batch_size, channels, h, w)\n",
    "      x = x.view((n, c, h, w))\n",
    "\n",
    "      # (batch_size, channels, h, w) -> (batch_size, channels, h, w)\n",
    "      x += residual\n",
    "\n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.groupnorm1= nn.GroupNorm(32, in_channels)\n",
    "        self. conv1= nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.groupnorm2= nn.GroupNorm(32, out_channels)\n",
    "        self.conv2= nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu= nn.ReLU()\n",
    "        \n",
    "        if in_channels == out_channels:\n",
    "            self.residual_layer= nn.Identity()\n",
    "        else:\n",
    "            self.residual_layer= nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n",
    "    def forward(self, x):\n",
    "        residual = x.clone()\n",
    "        x = self.groupnorm1(x)\n",
    "        x = F.selu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.groupnorm2(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        return x + self.residual_layer(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Sequential):\n",
    "    def  __init__(self):\n",
    "        super().__init__(\n",
    "            # (batch_size, channel, h, w) -> (batch_size, 128, h, w)\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
    "\n",
    "            # (batch_size, 128, h, w) -> (batch_size, 128, h, w)\n",
    "            ResidualBlock(128, 128),\n",
    "\n",
    "            # (batch_size, 128, h, w) -> (batch_size, 128, h / 2, w / 2)\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=0),\n",
    "\n",
    "            # (batch_size, 128, h / 2, w / 2) -> (batch_size, 256, h / 2, w / 2)\n",
    "            ResidualBlock(128, 256),\n",
    "\n",
    "            # (batch_size, 256, h / 2, w / 2) -> (batch_size, 256, h / 2, w / 2)\n",
    "            ResidualBlock(256, 256),\n",
    "\n",
    "            # (batch_size, 256, h / 2, w / 2) -> (batch_size, 256, h / 4, w / 4)\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=0),\n",
    "\n",
    "            # (batch_size, 256, h / 4, w / 4) -> (batch_size, 512, h / 4, w / 4)\n",
    "            ResidualBlock(256, 512),\n",
    "\n",
    "            # (batch_size, 512, h / 4, w / 4) -> (batch_size, 512, h / 4, w / 4)\n",
    "            ResidualBlock(512, 512),\n",
    "\n",
    "            # (batch_size, 512, h / 4, w / 4) -> (batch_size, 512, h / 8, w / 8)\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=0),\n",
    "\n",
    "            # (batch_size, 512, h / 8, w / 8) -> (batch_size, 512, h / 8, w / 8)\n",
    "            ResidualBlock(512, 512),\n",
    "\n",
    "            # (batch_size, 512, h / 8, w / 8) -> (batch_size, 512, h / 8, w / 8)\n",
    "            ResidualBlock(512, 512),\n",
    "\n",
    "            # (batch_size, 512, h / 8, w / 8) -> (batch_size, 512, h / 8, w / 8)\n",
    "            ResidualBlock(512, 512),\n",
    "\n",
    "            # (batch_size, 512, h / 8, w / 8) -> (batch_size, 512, h / 8, w / 8)\n",
    "            AttentionBlock(512),\n",
    "\n",
    "            # (batch_size, 512, h / 8, w / 8) -> (batch_size, 512, h / 8, w / 8)\n",
    "            ResidualBlock(512, 512),\n",
    "\n",
    "            # (batch_size, 512, h / 8, w / 8) -> (batch_size, 512, h / 8, w / 8)\n",
    "            nn.GroupNorm(32, 512),\n",
    "\n",
    "            # (batch_size, 512, h / 8, w / 8) -> (batch_size, 512, h / 8, w / 8)\n",
    "            nn.SiLU(),\n",
    "\n",
    "            # (batch_size, 512, h / 8, w / 8) -> (batch_size, 8, h / 8, w / 8)\n",
    "            nn.Conv2d(512, 8, kernel_size=3, padding=1),\n",
    "\n",
    "            # (batch_size, 8, h / 8, w / 8) -> (batch_size, 8, h / 8, w / 8)\n",
    "            nn.Conv2d(8, 8, kernel_size=1, padding=0)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, channel, h, w)\n",
    "\n",
    "        for module in self:\n",
    "            if isinstance(module, nn.Conv2d) and module.stride == (2, 2):\n",
    "                x = F.pad(x, (0, 1, 0, 1))  # (left, right, top, bottom)\n",
    "            x = module(x)\n",
    "\n",
    "        # (batch_size, 8, h / 8, w / 8) -> two tensors of shape (batch_size, 4, h / 8, w / 8)\n",
    "        mean, log_variance = torch.chunk(x, 2, dim=1)\n",
    "\n",
    "        # Clamp log variance between -30 and 20\n",
    "        log_variance = torch.clamp(log_variance, -30, 20)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        std = torch.exp(0.5 * log_variance)\n",
    "        eps = torch.randn_like(std)\n",
    "        x = mean + eps * std\n",
    "\n",
    "        # Scale the latent representation\n",
    "        x *= 0.18215\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(4, 512, kernel_size=3, padding=1),\n",
    "            ResidualBlock(512, 512),\n",
    "            AttentionBlock(512),\n",
    "            ResidualBlock(512, 512),\n",
    "            ResidualBlock(512, 512),\n",
    "            ResidualBlock(512, 512),\n",
    "            nn.Upsample(scale_factor=2),  # From 4x4 -> 8x8\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            ResidualBlock(512, 256),\n",
    "            ResidualBlock(256, 256),\n",
    "            nn.Upsample(scale_factor=2),  # From 8x8 -> 16x16\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            ResidualBlock(128, 128),\n",
    "            nn.Upsample(scale_factor=2),  # From 16x16 -> 32x32\n",
    "            nn.Conv2d(128, 3, kernel_size=3, padding=1),  # Final output channels = 3 (RGB)\n",
    "            nn.Tanh()  # Ensures outputs are in range [-1, 1] after normalization\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x /= 0.18215\n",
    "        for module in self:\n",
    "            x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch [1/10], Step [1/782], Loss: 0.8543, Recon Loss: 0.3869, KL Div: 1869.4482\n",
      "Epoch [1/10], Step [2/782], Loss: 1.0158, Recon Loss: 0.6289, KL Div: 1547.8093\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     28\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 29\u001b[0m     reconstructed, encoded \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     recon_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(reconstructed, images)\n\u001b[1;32m     31\u001b[0m     mean, log_variance \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mchunk(encoded, \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m      9\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 10\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoded, encoded\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.18215\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:544\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    534\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    535\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    543\u001b[0m     )\n\u001b[0;32m--> 544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "beta = 0.00025\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        reconstructed, encoded = model(images)\n",
    "        recon_loss = nn.MSELoss()(reconstructed, images)\n",
    "        mean, log_variance = torch.chunk(encoded, 2, dim=1)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_variance - mean.pow(2) - log_variance.exp())\n",
    "        loss = recon_loss + beta * kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], '\n",
    "              f'Loss: {loss.item():.4f}, Recon Loss: {recon_loss.item():.4f}, KL Div: {kl_div.item():.4f}')\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "print('Training finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Switch model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample a latent vector from a standard normal distribution with shape (1, 4, 7, 7)\n",
    "    latent = torch.randn(1, 4, 7, 7).to(device)\n",
    "    # Reverse the scaling applied in the encoder\n",
    "    latent = latent / 0.18215\n",
    "    \n",
    "    # Pass the latent vector through the decoder to generate an image\n",
    "    generated = model.decoder(latent)\n",
    "\n",
    "# The generated image tensor is of shape (1, 3, 56, 56)\n",
    "# Remove the batch dimension and bring the tensor to CPU\n",
    "generated_img = generated.squeeze(0).cpu()\n",
    "\n",
    "# Denormalize the image (the training normalization was: (x - 0.5) / 0.5)\n",
    "generated_img = generated_img * 0.5 + 0.5\n",
    "generated_img = torch.clamp(generated_img, 0, 1)\n",
    "\n",
    "# Convert to numpy array with shape (height, width, channels) for plotting\n",
    "generated_img = generated_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Plot the generated image\n",
    "plt.imshow(generated_img)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "from intelligraphs.data_loaders.loaders import IntelliGraphsDataLoader\n",
    "import torch\n",
    "\n",
    "data_load = IntelliGraphsDataLoader('syn-paths')\n",
    "train_data, val_data, test_data = data_load.load_torch()\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# Define Transformer Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: tensor([16,  1, 29])\n"
     ]
    }
   ],
   "source": [
    "# Checking the structure of train_data\n",
    "for batch in train_data:\n",
    "    print(\"Input Shape:\", batch[)  # Assuming key is 'input'\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Input Shape: torch.Size([3, 3])\n",
      "Adjacency Matrix Shape: torch.Size([3, 3])\n",
      "Relations Shape: torch.Size([3, 16])\n",
      "Mean Shape: torch.Size([3, 32])\n",
      "Log Variance Shape: torch.Size([3, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from intelligraphs.data_loaders.loaders import IntelliGraphsDataLoader\n",
    "\n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.layer = TransformerEncoderLayer(embed_dim, num_heads, ff_dim, dropout)\n",
    "        self.transformer = TransformerEncoder(self.layer, num_layers=3)  # 3 Transformer Blocks\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.transformer(x)\n",
    "\n",
    "# Variational Encoder\n",
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, latent_dim, num_entities, num_relations):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.entity_embedding = nn.Embedding(num_entities, embed_dim)\n",
    "        self.relation_embedding = nn.Embedding(num_relations, embed_dim)\n",
    "\n",
    "        self.transformer = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.mean_proj = nn.Linear(embed_dim, latent_dim)  # Projection for μ\n",
    "        self.logvar_proj = nn.Linear(embed_dim, latent_dim)  # Projection for log(σ)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 3, 3) -> entity, relation, entity\n",
    "        head, rel, tail = x[:, 0], x[:, 1], x[:, 2]  # Extract triplets\n",
    "\n",
    "        # Convert indices to embeddings\n",
    "        head_emb = self.entity_embedding(head)  # (batch_size, embed_dim)\n",
    "        rel_emb = self.relation_embedding(rel)  # (batch_size, embed_dim)\n",
    "        tail_emb = self.entity_embedding(tail)  # (batch_size, embed_dim)\n",
    "\n",
    "        # Stack instead of concatenate to match expected Transformer shape (batch_size, seq_len=3, embed_dim)\n",
    "        x = torch.stack([head_emb, rel_emb, tail_emb], dim=1)  # Shape: (batch_size, 3, embed_dim)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer(x)  # Output shape: (batch_size, 3, embed_dim)\n",
    "        x = torch.mean(x, dim=1)  # Mean pooling over sequence dimension -> (batch_size, embed_dim)\n",
    "\n",
    "        # Compute Variational Parameters\n",
    "        mu = self.mean_proj(x)  # (batch_size, latent_dim)\n",
    "        logvar = self.logvar_proj(x)  # (batch_size, latent_dim)\n",
    "\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "# Reparameterization Trick\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "# Variational Decoder\n",
    "class VariationalDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, embed_dim, num_heads, ff_dim, output_dim):\n",
    "        super(VariationalDecoder, self).__init__()\n",
    "        self.linear_proj = nn.Linear(latent_dim, embed_dim)  # Linear projection to initialize input\n",
    "        self.transformer = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.output_proj = nn.Linear(embed_dim, output_dim)  # Output projection\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.linear_proj(z).unsqueeze(1)  # Expand to sequence dimension\n",
    "        z = self.transformer(z)  # Transformer blocks\n",
    "        z = self.output_proj(z)  # Final LP layer\n",
    "        return z.squeeze(1)\n",
    "\n",
    "# Structure Decoder with Tensor Factorization\n",
    "class StructureDecoder(nn.Module):\n",
    "    def __init__(self, embed_dim, relation_dim, num_entities):\n",
    "        super(StructureDecoder, self).__init__()\n",
    "        self.entity_embedding = nn.Linear(embed_dim, num_entities)  # Map to entity embeddings\n",
    "        self.relation_embedding = nn.Linear(embed_dim, relation_dim)  # Map to relations\n",
    "\n",
    "    def forward(self, decoded_output):\n",
    "        entity_recon = self.entity_embedding(decoded_output)\n",
    "        relation_recon = self.relation_embedding(decoded_output)\n",
    "        adjacency_matrix = torch.matmul(entity_recon, entity_recon.transpose(0, 1))  # Factorized graph construction\n",
    "        return adjacency_matrix, relation_recon\n",
    "\n",
    "# Full FG-VAE Model\n",
    "class FG_VAE(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, latent_dim, output_dim, relation_dim, num_entities, num_relations):\n",
    "        super(FG_VAE, self).__init__()\n",
    "        self.encoder = VariationalEncoder(embed_dim, num_heads, ff_dim, latent_dim, num_entities, num_relations)\n",
    "        self.decoder = VariationalDecoder(latent_dim, embed_dim, num_heads, ff_dim, output_dim)\n",
    "        self.structure_decoder = StructureDecoder(embed_dim, relation_dim, num_entities)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        decoded_output = self.decoder(z)\n",
    "        adjacency_matrix, relations = self.structure_decoder(decoded_output)\n",
    "        return adjacency_matrix, relations, mu, logvar\n",
    "\n",
    "# Model Instantiation\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "ff_dim = 128\n",
    "latent_dim = 32\n",
    "output_dim = 64  # Same as embed_dim\n",
    "relation_dim = 16\n",
    "num_entities = 100  # Example: Number of unique entities\n",
    "num_relations = 20  # Example: Number of unique relations\n",
    "\n",
    "model = FG_VAE(embed_dim, num_heads, ff_dim, latent_dim, output_dim, relation_dim, num_entities, num_relations)\n",
    "\n",
    "# Load dataset\n",
    "# Load dataset\n",
    "data_load = IntelliGraphsDataLoader('syn-paths')\n",
    "train_loader, val_loader, test_loader = data_load.load_torch()\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# Get one batch from train_loader\n",
    "batch = next(iter(train_loader))  # Get the first batch\n",
    "\n",
    "# Ensure input is a tensor\n",
    "x = batch[0]  # Assuming the first element is the input data\n",
    "\n",
    "# Convert input to integer tensor if it's not already\n",
    "x = x.long()  # Ensure it's integer-based for embedding lookup\n",
    "\n",
    "print(\"Input Shape:\", x.shape)  # Expected: (batch_size, 3, 3)\n",
    "\n",
    "# Forward Pass\n",
    "adj_matrix, relations, mu, logvar = model(x)\n",
    "\n",
    "# Print Output Shapes\n",
    "print(\"Adjacency Matrix Shape:\", adj_matrix.shape)\n",
    "print(\"Relations Shape:\", relations.shape)\n",
    "print(\"Mean Shape:\", mu.shape)\n",
    "print(\"Log Variance Shape:\", logvar.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max entity index in dataset: 29, Model num_entities: 25\n",
      "Error: max entity index 29 exceeds num_entities 25.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Only check one batch\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Train Model with the existing dataset\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Evaluate Model with the existing dataset\u001b[39;00m\n\u001b[1;32m    109\u001b[0m evaluate_mrr(model, test_loader)\n",
      "Cell \u001b[0;32mIn[25], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlong()  \u001b[38;5;66;03m# Ensure integer inputs for embedding\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m adj_matrix, relations, mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Reconstruction Loss (Adjacency Matrix)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m recon_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(adj_matrix, torch\u001b[38;5;241m.\u001b[39meye(adj_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(adj_matrix\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 93\u001b[0m, in \u001b[0;36mFG_VAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 93\u001b[0m     mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     z \u001b[38;5;241m=\u001b[39m reparameterize(mu, logvar)\n\u001b[1;32m     95\u001b[0m     decoded_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m, in \u001b[0;36mVariationalEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m head, rel, tail \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m], x[:, \u001b[38;5;241m1\u001b[39m], x[:, \u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# Extract triplets\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Convert indices to embeddings\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m head_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, embed_dim)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m rel_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelation_embedding(rel)  \u001b[38;5;66;03m# (batch_size, embed_dim)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m tail_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity_embedding(tail)  \u001b[38;5;66;03m# (batch_size, embed_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# KL Divergence Loss\n",
    "def kl_divergence(mu, logvar):\n",
    "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "# Training Function\n",
    "def train(model, train_loader, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x = batch[0].long()  # Ensure integer inputs for embedding\n",
    "            adj_matrix, relations, mu, logvar = model(x)\n",
    "            \n",
    "            # Reconstruction Loss (Adjacency Matrix)\n",
    "            recon_loss = F.mse_loss(adj_matrix, torch.eye(adj_matrix.shape[0]).to(adj_matrix.device))\n",
    "\n",
    "            # KL Divergence\n",
    "            kl_loss = kl_divergence(mu, logvar)\n",
    "\n",
    "            # Total VAE Loss\n",
    "            loss = recon_loss + 0.1 * kl_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Evaluation Function: Mean Reciprocal Rank (MRR)\n",
    "def evaluate_mrr(model, test_loader):\n",
    "    model.eval()\n",
    "    ranks = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x = batch[0].long()\n",
    "            adj_matrix, relations, mu, logvar = model(x)\n",
    "\n",
    "            print(f\"adj_matrix shape: {adj_matrix.shape}\")  # Debugging\n",
    "            print(f\"x shape: {x.shape}\")  # Debugging\n",
    "\n",
    "            for i in range(x.shape[0]):  # Iterate over batch\n",
    "                head, rel, tail = x[i, 0].item(), x[i, 1].item(), x[i, 2].item()\n",
    "                print(f\"Head: {head}, Relation: {rel}, Tail: {tail}\")  # Debugging\n",
    "\n",
    "                # Check if head index is within bounds\n",
    "                if head >= adj_matrix.shape[0]:\n",
    "                    print(f\"Error: head index {head} is out of bounds for adj_matrix of shape {adj_matrix.shape}\")\n",
    "                    continue  # Skip this sample to prevent crashing\n",
    "\n",
    "                # Compute scores for all possible tails\n",
    "                scores = adj_matrix[head]  # Get similarity scores\n",
    "                sorted_scores = torch.argsort(scores, descending=True)\n",
    "\n",
    "                # Find rank of the correct tail\n",
    "                if tail >= sorted_scores.shape[0]:  # Ensure valid tail index\n",
    "                    print(f\"Error: tail index {tail} is out of bounds for sorted_scores of shape {sorted_scores.shape}\")\n",
    "                    continue\n",
    "\n",
    "                rank = (sorted_scores == tail).nonzero(as_tuple=True)[0].item() + 1  # Convert to 1-based index\n",
    "                ranks.append(1 / rank)\n",
    "\n",
    "    if len(ranks) == 0:\n",
    "        print(\"Warning: No valid ranks computed.\")\n",
    "        return 0.0\n",
    "\n",
    "    mrr = torch.tensor(ranks).mean().item()\n",
    "    print(f\"MRR: {mrr:.4f}\")\n",
    "    return mrr\n",
    "\n",
    "# Ensure `train_loader`, `val_loader`, and `test_loader` are passed from your existing dataset\n",
    "# If they are already defined, you can directly use them below:\n",
    "\n",
    "# Initialize Model\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "ff_dim = 128\n",
    "latent_dim = 32\n",
    "output_dim = 64  # Same as embed_dim\n",
    "relation_dim = 16\n",
    "num_entities = 100  # Example: Number of unique entities\n",
    "num_relations = 20  # Example: Number of unique relations\n",
    "\n",
    "# Initialize FG_VAE model (make sure the class definition exists)\n",
    "model = FG_VAE(embed_dim, num_heads, ff_dim, latent_dim, output_dim, relation_dim, num_entities, num_relations)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Ensure dataset entity range before training\n",
    "for batch in train_loader:\n",
    "    x = batch[0].long()\n",
    "    max_entity_index = x.max().item()\n",
    "    print(f\"Max entity index in dataset: {max_entity_index}, Model num_entities: {num_entities}\")\n",
    "    if max_entity_index >= num_entities:\n",
    "        print(f\"Error: max entity index {max_entity_index} exceeds num_entities {num_entities}.\")\n",
    "    break  # Only check one batch\n",
    "\n",
    "# Train Model with the existing dataset\n",
    "train(model, train_loader, optimizer, num_epochs=10)\n",
    "\n",
    "# Evaluate Model with the existing dataset\n",
    "evaluate_mrr(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1795.6851\n",
      "Epoch 2/10, Loss: 1605.1674\n",
      "Epoch 3/10, Loss: 1366.9462\n",
      "Epoch 4/10, Loss: 1142.8964\n",
      "Epoch 5/10, Loss: 1015.8445\n",
      "Epoch 6/10, Loss: 969.8641\n",
      "Epoch 7/10, Loss: 930.0904\n",
      "Epoch 8/10, Loss: 912.6677\n",
      "Epoch 9/10, Loss: 898.3297\n",
      "Epoch 10/10, Loss: 912.6243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3300.00it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2849.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2777.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2717.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3177.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2459.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3021.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3521.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2676.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2722.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2892.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2915.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2910.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2702.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1910.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1975.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2523.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2704.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2857.16it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2510.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2692.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3484.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3677.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3144.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1525.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2987.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3371.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3533.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2192.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3468.28it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3930.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2981.73it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1989.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2589.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3433.26it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2546.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2955.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3667.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2011.98it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2281.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3645.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3694.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2835.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2086.03it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4114.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2944.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2504.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2232.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3654.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3459.70it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1944.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2367.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3663.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2172.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2901.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3461.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2212.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2615.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3369.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3125.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2664.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3558.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3130.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3029.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2788.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2519.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3570.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3051.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2209.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3138.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2564.28it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2407.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3029.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3571.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3221.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1349.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3184.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3424.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3128.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2204.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2641.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4255.30it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3154.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2001.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3247.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2826.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2565.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3264.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2611.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2427.26it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2232.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3147.30it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3096.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2737.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2798.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3043.03it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2955.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2577.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2976.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3093.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2657.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2066.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2284.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2964.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2172.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2996.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2348.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1794.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3275.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3537.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2248.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2245.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3212.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2568.47it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2570.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2590.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2910.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3359.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2848.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2990.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1675.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2714.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3423.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2851.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2176.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3443.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3856.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2423.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2158.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2228.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2222.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3472.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2299.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1989.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2670.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4195.70it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2710.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2512.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2005.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1946.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3066.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3575.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1508.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2755.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4373.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2788.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2267.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2864.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3614.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2115.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2678.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2460.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2579.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4190.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3058.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1854.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2178.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4026.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2438.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1840.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1882.26it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3017.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3956.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1470.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2070.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3649.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2170.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2744.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2313.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2419.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2076.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1422.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2159.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2350.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1952.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2115.49it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2045.00it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2195.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1795.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2884.00it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2209.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1584.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2737.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2944.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1939.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3348.30it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1672.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2267.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2120.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2307.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2013.59it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2184.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2380.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2652.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2464.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2309.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2009.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3326.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1659.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2559.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2394.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2754.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2686.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1726.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1416.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1498.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 261.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2398.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2001.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2678.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3731.59it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1454.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2604.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3344.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1623.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1653.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2286.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1565.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2707.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1870.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2132.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2842.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2099.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3061.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1940.31it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1913.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1835.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1860.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2389.01it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1996.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1610.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2227.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2464.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2276.21it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2433.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2606.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2425.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3048.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2221.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1978.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3061.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2221.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2382.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2537.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3774.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1948.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2388.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2862.35it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2211.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1890.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2097.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2540.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2131.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2453.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2615.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 383.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 533.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1389.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2366.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3318.28it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2476.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1742.30it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2765.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1704.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1640.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2667.00it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3181.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2423.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2645.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2666.44it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1938.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2920.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3197.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2003.01it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2071.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2139.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1981.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 250.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1781.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1623.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2323.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1952.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2061.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2279.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2452.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1780.26it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2825.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2629.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1797.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2202.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2188.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1961.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1972.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2435.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1883.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2392.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1967.31it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2502.07it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3731.59it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2008.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3359.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2879.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3005.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1884.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2924.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2320.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2025.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2262.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2289.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2102.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2144.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3325.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3421.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2460.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1804.00it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2995.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2153.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3313.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2375.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2448.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2325.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1749.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 174.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2514.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1822.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2993.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2390.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1935.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1873.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2631.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2213.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2568.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1564.07it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2798.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3066.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 251.27it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1062.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2254.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2254.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2232.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2026.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2814.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1880.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3504.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1548.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1885.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2296.99it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2352.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1978.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2130.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1758.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2145.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3074.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2395.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3236.35it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1802.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3381.59it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1856.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1782.28it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3580.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2590.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1410.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2870.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2253.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2459.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2554.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2725.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2220.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2907.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2494.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1899.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2910.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1514.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1914.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2731.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2563.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3177.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1779.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3124.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3420.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2485.27it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2093.31it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2093.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 540.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2425.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 705.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2820.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2105.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2245.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2535.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2540.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2512.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3322.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2678.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3082.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2615.45it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3249.72it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2181.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1800.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2381.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3160.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2102.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2192.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3268.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1914.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2710.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3639.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3086.32it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1678.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2803.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2023.30it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2819.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2586.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2851.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1820.44it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3336.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1845.00it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3727.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2599.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1592.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2473.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1991.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2830.16it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2033.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3587.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2407.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2798.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2286.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2235.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2277.45it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3730.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1732.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3382.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2007.80it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2194.44it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2666.44it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 657.35it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1657.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2599.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1936.73it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3319.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2219.21it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2166.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2760.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2386.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2870.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1682.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1742.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2010.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2674.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2424.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2351.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2652.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2121.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2647.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3171.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2267.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1964.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2964.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1730.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2411.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2737.80it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1813.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1183.49it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2114.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1866.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2289.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1960.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1934.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2746.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2849.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2453.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2248.96it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2517.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2462.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2479.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2455.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1863.31it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1913.46it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2704.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2882.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2918.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2997.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2588.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1619.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1850.70it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2714.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2111.23it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 395.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2183.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3352.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3393.45it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1732.47it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3137.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2969.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1682.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2442.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1949.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1755.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2737.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3459.70it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2425.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3030.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1892.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2371.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2205.59it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1657.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2455.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 227.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3012.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2060.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1985.31it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2901.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2403.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2683.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2638.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2214.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3680.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1809.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2027.21it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3983.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2410.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2790.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1737.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1843.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2015.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2773.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2352.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3401.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2204.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2047.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2464.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 850.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3212.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2893.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2371.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3562.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2608.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2152.03it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3605.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2341.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2851.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2573.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2364.32it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2931.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2011.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3185.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 253.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1853.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2773.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3253.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2452.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2010.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2265.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2924.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2394.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3058.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2617.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2313.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1556.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 696.38it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1534.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1211.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3671.70it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3221.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1673.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3726.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2626.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2572.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1937.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3247.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1941.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2734.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1497.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2039.37it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3051.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2996.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2083.26it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1671.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3460.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 237.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2136.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2866.27it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2506.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3754.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2661.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1671.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2219.21it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1780.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1423.25it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2964.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2041.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4587.28it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3576.72it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2071.60it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2003.97it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3232.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2161.27it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2302.45it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1092.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2255.41it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2525.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2399.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3311.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2809.31it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2676.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3282.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2320.71it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3000.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2697.30it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1652.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3282.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2873.47it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2382.68it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1413.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2985.27it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2122.98it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1730.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2710.08it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1631.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3233.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2898.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2450.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2014.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2519.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation - Mean Rank (MRR): 24.25, Hits@10: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import TransE\n",
    "from torch_geometric.loader import DataLoader\n",
    "from intelligraphs.data_loaders.loaders import IntelliGraphsDataLoader  # Your dataset loader\n",
    "\n",
    "# ========================\n",
    "# Define Parameters\n",
    "# ========================\n",
    "embed_dim = 64\n",
    "num_entities = 100  # Adjust based on your dataset\n",
    "num_relations = 20  # Adjust based on your dataset\n",
    "\n",
    "# ========================\n",
    "# Initialize TransE Model\n",
    "# ========================\n",
    "model = TransE(num_nodes=num_entities, num_relations=num_relations, hidden_channels=embed_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ========================\n",
    "# Load IntelliGraphs Dataset\n",
    "# ========================\n",
    "data_load = IntelliGraphsDataLoader('syn-paths')\n",
    "train_loader, val_loader, test_loader = data_load.load_torch()\n",
    "\n",
    "# ========================\n",
    "# Training Function\n",
    "# ========================\n",
    "def train(model, data_loader, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x = batch[0].long()  # Ensure integer input for embeddings\n",
    "            loss = model.loss(x[:, 0], x[:, 1], x[:, 2])  # (head, relation, tail)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# ========================\n",
    "# Evaluation Function (MRR & Hits@10)\n",
    "# ========================\n",
    "@torch.no_grad()\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    mean_ranks, hits_at_10s = [], []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        x = batch[0].long()\n",
    "        heads, relations, tails = x[:, 0], x[:, 1], x[:, 2]\n",
    "\n",
    "        # Capture all returned values\n",
    "        result = model.test(heads, relations, tails, batch_size=1000, k=10)\n",
    "\n",
    "        # Unpack based on the number of values returned\n",
    "        if isinstance(result, tuple) and len(result) >= 2:\n",
    "            mean_rank, hits_at_10 = result[:2]  # Extract the first two values\n",
    "            mean_ranks.append(mean_rank)\n",
    "            hits_at_10s.append(hits_at_10)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    avg_mean_rank = sum(mean_ranks) / len(mean_ranks)\n",
    "    avg_hits_at_10 = sum(hits_at_10s) / len(hits_at_10s)\n",
    "\n",
    "    print(f\"Final Evaluation - Mean Rank (MRR): {avg_mean_rank:.2f}, Hits@10: {avg_hits_at_10:.4f}\")\n",
    "\n",
    "# Run Evaluation\n",
    "\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Run Training & Evaluation\n",
    "# ========================\n",
    "train(model, train_loader, optimizer, num_epochs=10)\n",
    "evaluate(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 219.406860\n",
      "Epoch 200: Loss = 68.305603\n",
      "Epoch 400: Loss = 26.170866\n",
      "Epoch 600: Loss = 13.507149\n",
      "Epoch 800: Loss = 11.020437\n",
      "Epoch 1000: Loss = 10.159431\n",
      "Epoch 1200: Loss = 9.395856\n",
      "Epoch 1400: Loss = 9.836242\n",
      "Epoch 1600: Loss = 10.719400\n",
      "Epoch 1800: Loss = 11.270818\n",
      "Epoch 2000: Loss = 9.899794\n",
      "Epoch 2200: Loss = 10.065038\n",
      "Epoch 2400: Loss = 10.294238\n",
      "Epoch 2600: Loss = 10.090910\n",
      "Epoch 2800: Loss = 9.850412\n",
      "Epoch 3000: Loss = 10.820418\n",
      "Epoch 3200: Loss = 9.895985\n",
      "Epoch 3400: Loss = 9.233746\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 96\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# Compute loss based on Hamilton’s equations (corrected signs)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((grad_H[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m batch_dX[:, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m  \u001b[38;5;66;03m# dq/dt = ∂H/∂p\u001b[39;00m\n\u001b[1;32m     94\u001b[0m                       (grad_H[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m batch_dX[:, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# dp/dt = -∂H/∂q\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:288\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/python3.10/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
